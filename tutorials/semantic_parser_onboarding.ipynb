{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKzm8_U2aJNR"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/facebookresearch/droidlet/blob/master/tutorials/semantic_parser_onboarding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVCwKqEckiVq"
   },
   "source": [
    "# Semantic Parser Onboarding\n",
    "\n",
    "The **semantic parser** is a seq-to-seq model built on the Huggingface Transformers library. The input to the parser is a chat command, eg. \"build a red cube\". The output is a linearized parse tree (see [Action Dictionary Spec Doc](https://github.com/fairinternal/minecraft/blob/master/craftassist/agent/documents/Action_Dictionary_Spec.md) for the grammar specification).\n",
    "\n",
    "The encoder uses a pretrained DistilBERT model, followed by a highway transformation. For the default model, encoder parameters are frozen during training. The decoder consists of a 6-layer Transformer, and has a **Language Modeling** head, **span** beginning and span end heads, and **text span** beginning and end heads. The Language Modeling head predicts the next node in the linearized tree. The span heads predict the span range, which provides the value for the span node. For more details, see the [Craftassist Paper](https://www.aclweb.org/anthology/2020.acl-main.427.pdf).\n",
    "\n",
    "This tutorial covers the end-to-end process of how to train a semantic parser model and use it in the CraftAssist agent:\n",
    "\n",
    "*  Generating and preparing datasets\n",
    "*  Training models\n",
    "* Evaluating models\n",
    "* Using models in the agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ygCXenKCi8A"
   },
   "source": [
    "## Set Up\n",
    "\n",
    "### Downloading Pre-Trained Models and Datasets\n",
    "\n",
    "When you run the CraftAssist agent for the first time, the pre-trained models and data files required by the project are downloaded automatically from S3.\n",
    "\n",
    "```\n",
    "cd ~/minecraft/craftassist\n",
    "python ./agent/craftassist_agent.py\n",
    "```\n",
    "\n",
    "You can also do this manually:\n",
    "\n",
    "```\n",
    "cd ~/minecraft\n",
    "./tools/data_scripts/compare_directory_hash.sh\n",
    "```\n",
    "\n",
    "This script checks your local paths `craftassist/agent/models` and `craftassist/agent/datasets` for updates, and downloads the files from S3 if your local files are missing or outdated (optional).\n",
    "\n",
    "### Conda Env\n",
    "\n",
    "First make sure you set up your conda environment as per the [README instructions](https://github.com/fairinternal/minecraft/blob/master/README.md).\n",
    "\n",
    "Depending on your GPU driver version, you may need to downgrade your pytorch and CUDA versions. As of this writing, FAIR machines have installed NVIDIA driver version 10010, which is compatible with pytorch 1.5.1 and cudatoolkit 10.1. To update your conda env with these versions, run\n",
    "```\n",
    "conda install pytorch==1.5.1 torchvision==0.6.1 cudatoolkit=10.1 -c pytorch\n",
    "```\n",
    "\n",
    "For a list of pytorch and CUDA compatible versions, see: https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h6Nr7Dx1SSP"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "The datasets we use to train the semantic parsing models consist of:\n",
    "* **Templated**: This file has 800K dialogue, action dictionary pairs generated using our generation script.\n",
    "    * **Templated Modify**: This file has 100K dialogue, action dictionary pairs generated in the same way as templated.txt, except covering modify type commands, eg. \"make this hole larger\".\n",
    "* **Annotated**: This file contains 7k dialogue, action dictionary pairs. These are human labelled examples obtained from crowd sourced tasks and in game interactions.\n",
    "\n",
    "See the CraftAssist paper for more information on how datasets are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBDOjbOXAo3d"
   },
   "source": [
    "We provide all the dialogue datasets we use in the CraftAssist project in a public S3 folder: \n",
    "https://craftassist.s3-us-west-2.amazonaws.com/pubr/dialogue_data.tar.gz\n",
    "\n",
    "In addition to the datasets used to train the model, this folder also contains greetings and short commands that the agent queries during gameplay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0SPXWga38M7"
   },
   "source": [
    "### Generating Datasets\n",
    "\n",
    "This section describes how to use our tools to generate and process training data.\n",
    "\n",
    "To generate some templated data to train the model on, run this script with the number of examples you want to generate, eg. 500K examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gpKV_bjkIc_",
    "outputId": "00b670f6-0c2f-4bac-cc2d-642e30a46a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: /root/minecraft/base_agent/ttad/generation_dialogues: No such file or directory\n",
      "python3: can't open file 'generate_dialogue.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! cd ~/minecraft/base_agent/ttad/generation_dialogues\n",
    "! python generate_dialogue.py -n 500000 > generated_dialogues.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mirbvp1_4sUU"
   },
   "source": [
    "This creates a text file. We next pre-process the data into the format required by the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkYMEoYP4yG5",
    "outputId": "dbb4965d-1220-4162-f86e-fa5cc106c986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: ../ttad_transformer_model/: No such file or directory\n",
      "python3: can't open file 'data_scripts/preprocess_templated.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! cd ../ttad_transformer_model/\n",
    "! python data_scripts/preprocess_templated.py \\\n",
    "--raw_data_path ../generation_dialogues/generated_dialogues.txt \\\n",
    "--output_path [OUTPUT_PATH (file must be named templated.txt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r_PxlAaAbPA"
   },
   "source": [
    "The format of each row is \n",
    "```\n",
    "[TEXT]|[ACTION DICTIONARY]\n",
    "```\n",
    "\n",
    "To create train/test/valid splits of the data, run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJBMiU_o-loR",
    "outputId": "2e41ea60-05f2-4099-d249-64823810f539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file 'data_scripts/create_annotated_split.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! python data_scripts/create_annotated_split.py \\\n",
    "--raw_data_path [PATH_TO_DATA_DIR] \\\n",
    "--output_path [PATH_TO_SPLIT_FOLDERS] \\\n",
    "--filename \"templated.txt\" \\\n",
    "--split_ratio \"0.7:0.2:0.1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-E-iLb8eGNe"
   },
   "source": [
    "To create a split of annotated data too, simply run the above, but with filename \"annotated.txt\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlrcJguQ_FxW"
   },
   "source": [
    "We are now ready to train the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9DtuFQwkEGg",
    "outputId": "14dfc729-ec9e-4ca3-e1ce-6a8417d7e534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: cd: /root/minecraft: No such file or directory\n",
      "python3: can't open file 'base_agent/ttad/ttad_transformer_model/train_model.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! cd ~/minecraft\n",
    "! python base_agent/ttad/ttad_transformer_model/train_model.py \\\n",
    "--data_dir craftassist/agent/models/ttad_bert_updated/annotated_data/ \\\n",
    "--dtype_samples '[[\"templated\", 0.35], [\"templated_modify\", 0.05], [\"annotated\", 0.6]]' \\\n",
    "--tree_voc_file craftassist/agent/models/ttad_bert_updated/models/caip_test_model_tree.json \\\n",
    "--output_dir $CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCh8Dot4_NcQ"
   },
   "source": [
    "Feel free to experiment with the model parameters. The models and tree vocabulary files are saved under $CHECKPOINT_PATH, along with a log that contains training and validation accuracies after every epoch. Once you're done, you can choose which epoch you want the parameters for, and use that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYRQmBV3-zSO"
   },
   "source": [
    "You can take the params of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bx04vfC8_bZW",
    "outputId": "682ec505-1ae7-4616-94cf-1958f5de416a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: missing destination file operand after 'craftassist/agent/models/caip_test_model.pth'\n",
      "Try 'cp --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "! cp $PATH_TO_BEST_CHECKPOINT_MODEL craftassist/agent/models/caip_test_model.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0z1Rih4HJA6"
   },
   "source": [
    "## Testing Models\n",
    "\n",
    "During training, validation accuracy after every epoch is calculated and logged. You can access the log file in the output directory, where the checkpointed models are also saved.\n",
    "\n",
    "To calculate accuracy on the test set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZcaRqK5ljR5"
   },
   "outputs": [],
   "source": [
    "# eval_model code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EICCQmMIMXE"
   },
   "source": [
    "You can test the model using our inference script:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2Ye2CZsH8qm"
   },
   "outputs": [],
   "source": [
    "! python3 -i base_agent/ttad/ttad_transformer_model/test_model_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "__n2-rpTll4z",
    "outputId": "3b14e779-9c8d-461f-9885-1d2fa11007a5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-749f4f51cba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_beam_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dig a hole\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_beam_tree' is not defined"
     ]
    }
   ],
   "source": [
    "get_beam_tree(\"dig a hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ8gahV8lkjW"
   },
   "outputs": [],
   "source": [
    "## how to load iinto agent, ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqEmaJJ-_gfm"
   },
   "source": [
    "You can now use that model to run the agent."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Craftassist_onboarding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
