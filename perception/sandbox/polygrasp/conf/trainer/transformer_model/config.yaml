_target_: temporal_task_planner.trainer.transformer.configs.TransformerTaskPlannerConfig
num_instances: 60 
d_model: ${d_model}
nhead: 2
d_hid: ${d_hid}
num_slots: ${num_slots}
slot_iters: ${slot_iters}
num_encoder_layers: ${num_encoder_layers}
num_decoder_layers: ${num_decoder_layers}
dropout: 0.
batch_first: True
category_embed_size: ${category_embed_size}
pose_embed_size: ${pose_embed_size}
temporal_embed_size: ${temporal_embed_size}
marker_embed_size: ${marker_embed_size}